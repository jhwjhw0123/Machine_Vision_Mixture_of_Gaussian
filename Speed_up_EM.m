function r = Speed_up_EM

%The goal of this practical is to generate some data from an n-Dimensional
%mixtures of Gaussians model, and subsequently to fit an
%n-dimensional mixtures of Gaussians model to it to recover the original
%parameters

%You should use this template for your code and fill in the missing 
%sections marked "TO DO"

%close all open plots
close all;
clc;
clear;
startTime = tic;
%define true parameters for mixture of k Gaussians
%we will represent the mixtures of Gaussians as a Matlab structure
%in d dimenisions, the mean field
%will be a dxk matrix and the cov field will be a dxdxk matrix.
mixGaussTrue.k = 3;
mixGaussTrue.d = 2;
mixGaussTrue.weight = [0.1309 0.3966 0.4725];
mixGaussTrue.mean(:,1) = [ 4.0491 ; 4.8597];
mixGaussTrue.mean(:,2) = [ 7.7578 ; 1.6335];
mixGaussTrue.mean(:,3) = [11.9945 ; 8.9206];
mixGaussTrue.cov(:,:,1) = [  4.2534    0.4791;  0.4791    0.3522];         %Cov of 1st Gaussian
mixGaussTrue.cov(:,:,2) = [  0.9729    0.8723;  0.8723    2.6317];         %Cov of 2nd Gaussian
mixGaussTrue.cov(:,:,3) = [  0.9886   -1.2244; -1.2244    3.0187];         %Cov of 3rd Gaussian

%define number of samples to generate
nData = 400;

%generate data from the mixture of Gaussians
%TO DO - fill in this routine (below)
data = mixGaussGen(mixGaussTrue,nData);

%draw data, true Gaussians
figure;
drawEMData2d(data,mixGaussTrue);
drawnow;


%define number of components to estimate
nGaussEst = 3;

%fit mixture of Gaussians
%TO DO fill in this routine (below)
figure;
mixGaussEst = fitMixGauss(data,nGaussEst);
toc(startTime);



%==========================================================================
%==========================================================================

%the goal of this function is to generate data from a k-dimensional
%mixtures of Gaussians structure.
function data = mixGaussGen(mixGauss,nData)

%create space for output data
data = zeros(mixGauss.d,nData);
%for each data point
for cData =1:1:nData
    %randomly choose Gaussian according to probability distributions
    h = sampleFromDiscrete(mixGauss.weight);
    %draw a sample from the appropriate Gaussian distribution
    %first sample from the covariance matrix (google how to do this - it
    %will involve the Matlab command 'chol').  Then add the mean vector
    %TO DO (f)- replace this
    data(:,cData) = mvnrnd(mixGauss.mean(:,h),mixGauss.cov(:,:,h));
    %data(:,cData) = mixGauss.cov(:,:,h)*randn(mixGauss.d,1) + mixGauss.mean(:,h);
end
    
%==========================================================================
%==========================================================================

function mixGaussEst = fitMixGauss(data,k)
        
[nDim, nData] = size(data);

%MAIN E-M ROUTINE 
%there are nData data points, and there is a hidden variable associated
%with each.  If the hidden variable is 0 this indicates that the data was
%generated by the first Gaussian.  If the hidden variable is 1 then this
%indicates that the hidden variable was generated by the second Gaussian
%etc.

postHidden = zeros(k, nData);      %%In one dimension it is called Responsibilities

%in the E-M algorithm, we calculate a complete posterior distribution over
%the (nData) hidden variables in the E-Step.  In the M-Step, we
%update the parameters of the Gaussians (mean, cov, w).  

%we will initialize the values to random values
mixGaussEst.d = nDim;
mixGaussEst.k = k;
mixGaussEst.weight = (1/k)*ones(1,k);
mixGaussEst.mean = 2*randn(nDim,k);
for cGauss =1:1:k
    mixGaussEst.cov(:,:,cGauss) = (0.5+1.5*rand(1))*eye(nDim,nDim);        %Diagonal Cov Matrix
end

%calculate current likelihood(Total Likelihood)
%TO DO - fill in this routine
logLike = getMixGaussLogLike(data,mixGaussEst);
fprintf('Log Likelihood Iter 0 : %4.3f\n',logLike);

nIter = 20;
for cIter = 1:1:nIter
    
  %E-step
  %MarginalEstep = zeros(1,nData);
  HiddenLike = HiddenLikeCal(mixGaussEst,data);
  HiddenJoint = zeros(mixGaussEst.k,nData);
  %Likelihood*Prior of h, comparing to MarginalEstep, I call it 'HiddenJoint'
  %(Don't take the name seriously, I'm a non-native speaker ^_^)
  for GaussianInd = 1:1:mixGaussEst.k
      HiddenJoint(GaussianInd,:) = HiddenLike(GaussianInd,:)*mixGaussEst.weight(GaussianInd);
  end
  %Our new 'MarginalEstep' is a Cool Matrix!
  MarginalEstep = repmat(sum(HiddenJoint,1),3,1);
  postHidden = HiddenJoint./MarginalEstep;
  
  %Maximization Step
  SumpostHidden = zeros(k,1);
  for indx = 1:1:k
       SumpostHidden(indx) = sum(postHidden(indx,:));
  end
  TotalpostHidden = sum(SumpostHidden);
  %for each constituent Gaussian
  for cGauss = 1:1:k 
       %TO DO (h):  Update weighting parameters mixGauss.weight based on the total
       %posterior probability associated with each Gaussian. Replace this:
       mixGaussEst.weight(cGauss) = SumpostHidden(cGauss)/TotalpostHidden; 
        
       %TO DO (i):  Update mean parameters mixGauss.mean by weighted average
       %where weights are given by posterior probability associated with
       %Gaussian.  Replace this:
       %Using Matrix Calculation, Solve mixGaussEst.mean(:,cGauss) quickly
       %Cooooooooooooool
       mixGaussEst.mean(:,cGauss) = (postHidden(cGauss,:)*data.').'/SumpostHidden(cGauss);
       %TO DO (j):  Update covarance parameter based on weighted average of
       %square distance from update mean, where weights are given by
       %posterior probability associated with Gaussian
       %Speed-up: Using Vector Calculation to replace for loop! Cooool!
       cData = 1:1:nData;
       postCalcuHidden = repmat(postHidden(cGauss,:),2,1);
       mixGaussEst.cov(:,:,cGauss) = (postCalcuHidden.*(data(:,cData)-mixGaussEst.mean(:,cGauss)*ones(1,nData)))*((data(:,cData)-mixGaussEst.mean(:,cGauss)*ones(1,nData)).')/SumpostHidden(cGauss);
   end
   
   %draw the new solution
   drawEMData2d(data,mixGaussEst);drawnow;

   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood Iter %d : %4.3f\n',cIter,logLike);

end


%==========================================================================
%==========================================================================

%the goal of this routine is to calculate the log likelihood for the whole
%data set under a mixture of Gaussians model. We calculate the log as the
%likelihood will probably be a very small number that Matlab may not be
%able to represent.
%This is our new matrix operation Likelihood Function! Cooool!
function logLike = getMixGaussLogLike(data,mixGaussEst)
[nDim,nData] = size(data);   
cData = 1:1:nData;
cGaussian = (1:1:mixGaussEst.k).';
Weights = diag(diag(repmat(mixGaussEst.weight(cGaussian),3,1)));
HiddenLike = [];
for cGaussian = 1:1:mixGaussEst.k
      sigma = mixGaussEst.cov(:,:,cGaussian);
      mu = mixGaussEst.mean(:,cGaussian)*ones(1,400);
      ThisHiddenLike = (det(2*pi*sigma)^(-0.5))*exp(sum((-0.5*((data(:,cData)-mu)).*mldivide(sigma,(data(:,cData)-mu))),1));
      HiddenLike = [HiddenLike; ThisHiddenLike];
end
LoglikeMatrix = Weights*HiddenLike;
logLike = sum(log(sum(LoglikeMatrix,1)));


%==========================================================================
%==========================================================================

%The goal fo this routine is to draw the data in histogram form and plot
%the mixtures of Gaussian model on top of it.
function r = drawEMData2d(data,mixGauss)


set(gcf,'Color',[1 1 1]);
plot(data(1,:),data(2,:),'k.');

for cGauss = 1:1:mixGauss.k
    drawGaussianOutline(mixGauss.mean(:,cGauss),mixGauss.cov(:,:,cGauss),mixGauss.weight(cGauss));
    hold on;
end
plot(data(1,:),data(2,:),'k.');
axis square;axis equal;
axis off;
hold off;drawnow;

    


%=================================================================== 
%===================================================================

%draw 2DGaussian
function r= drawGaussianOutline(m,s,w)

hold on;
angleInc = 0.1;

c = [0.9*(1-w) 0.9*(1-w) 0.9*(1-w)];


for (cAngle = 0:angleInc:2*pi)
    angle1 = cAngle;
    angle2 = cAngle+angleInc;
    [x1, y1] = getGaussian2SD(m,s,angle1);
    [x2, y2] = getGaussian2SD(m,s,angle2);
    plot([x1 x2],[y1 y2],'k-','LineWidth',2,'Color',c);
end

%===================================================================
%===================================================================

%find position of in xy co-ordinates at 2SD out for a certain angle
function [x,y]= getGaussian2SD(m,s,angle1)

if (size(s,2)==1)
    s = diag(s);
end

vec = [cos(angle1) sin(angle1)];
factor = 4/(vec*inv(s)*vec');

x = cos(angle1) *sqrt(factor);
y = sin(angle1) *sqrt(factor);

x = x+m(1);
y = y+m(2);

%==========================================================================
%==========================================================================

%draws a random sample from a discrete probability distribution using a
%rejection sampling method
function r = sampleFromDiscrete(probDist)

nIndex = length(probDist);
while(1)
    %choose random index
    r = ceil(rand(1)*nIndex);
    %choose random height
    randHeight = rand(1);
    %if height is less than probability value at this point in the
    %histogram then select
    if (randHeight<probDist(r))
        break;
    end
end
%==========================================================================
%==========================================================================
function [HiddenLike] = HiddenLikeCalPrevious(mixGaussEst,data)
  [nDim, nData] = size(data);
  cData = 1:1:nData;
  HiddenLike1 = zeros(1,nData);
  HiddenLike2 = zeros(1,nData);
  HiddenLike3 = zeros(1,nData);
  sigma1 = mixGaussEst.cov(:,:,1);
  sigma2 = mixGaussEst.cov(:,:,2);
  sigma3 = mixGaussEst.cov(:,:,3);
  mu1 = mixGaussEst.mean(:,1)*ones(1,400);
  mu2 = mixGaussEst.mean(:,2)*ones(1,400);
  mu3 = mixGaussEst.mean(:,3)*ones(1,400);
  HiddenLike1 = (det(2*pi*sigma1)^(-0.5))*exp(sum((-0.5*((data(:,cData)-mu1)).*mldivide(sigma1,(data(:,cData)-mu1))),1));
  HiddenLike2 = (det(2*pi*sigma2)^(-0.5))*exp(sum(-0.5*((data(:,cData)-mu2)).*mldivide(sigma2,(data(:,cData)-mu2)),1));
  HiddenLike3 = (det(2*pi*sigma3)^(-0.5))*exp(sum(-0.5*((data(:,cData)-mu3)).*mldivide(sigma3,(data(:,cData)-mu3)),1));
  HiddenLike = [HiddenLike1;HiddenLike2;HiddenLike3];

function [HiddenLike] = HiddenLikeCal(mixGaussEst,data)
[nDim, nData] = size(data);
cData = 1:1:nData;
HiddenLike = [];
for cGaussian = 1:1:mixGaussEst.k
      sigma = mixGaussEst.cov(:,:,cGaussian);
      mu = mixGaussEst.mean(:,cGaussian)*ones(1,400);
      ThisHiddenLike = (det(2*pi*sigma)^(-0.5))*exp(sum((-0.5*((data(:,cData)-mu)).*mldivide(sigma,(data(:,cData)-mu))),1));
      HiddenLike = [HiddenLike; ThisHiddenLike];
end